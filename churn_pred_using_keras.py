# -*- coding: utf-8 -*-
"""perceptron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yvp5C8aGhAnBvdZoOP-mZFU7689YEswZ
"""



from sklearn.datasets import make_classification
import numpy as np
X , y = make_classification(n_samples = 100,n_features=2,n_informative = 1,n_redundant=0,n_classes = 2,n_clusters_per_class = 1,random_state = 2,hypercube=False,class_sep = 15)

import matplotlib.pyplot as plt
plt.figure(figsize=(10,6))
plt.scatter(X[:,0],X[:,1],c=y,cmap ='winter',s=100)

def perceptron(X,y):
  w1=w2=b=1
  lr = 0.1
  for j in range(1000):
    for i in range(X.shape[0]):
      #check condition
      z = w1*X[i][0] + w2*X[i][1] + b

      if z*y[i] < 0:
        w1 = w1 + lr *y[i] * x[i][0]
        w2 = w2 + lr *y[i] * x[i][1]
        b = b + lr * y[i]

  return w1,w2,b

w1 , w2, b = perceptron(X,y)

b

m = -(w1/w2)
c = -(b/w2)

print(m, c)

x_input = np.linspace(-3,3,100)
y_input = m * x_input + c
plt.figure(figsize=(10,6))
plt.plot(x_input,y_input,color='red',linewidth=3)
plt.scatter(X[:,0],X[:,1],c=y,cmap = 'winter',s = 100)
#plt.ylim(-3,2)

#deep lerning back propagation
#using keras libary
import pandas as pd
#customer churn predection
df = pd.read_csv('/content/Churn_Modelling.csv')

df.head()

df.duplicated().sum()

df['Exited'].value_counts()

df['Geography'].value_counts()

df['Gender'].value_counts()

df.drop(columns = ['RowNumber','CustomerId','Surname'],inplace = True)

df.head()

df =pd.get_dummies(df,columns =['Geography','Gender'],drop_first = 1)

df.head()

X = df.drop(columns=['Exited'])
y = df['Exited']
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 1)

X_train.shape
#y_train.shape

from sklearn.preprocessing import StandardScaler
Scaler = StandardScaler()
X_train_scaled = Scaler.fit_transform(X_train)
X_test_scaled = Scaler.transform(X_test)

X_train_scaled

import tensorflow
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

#sequwntial model
model = Sequential()
model.add(Dense(3,activation = 'sigmoid',input_dim = 11))
model.add(Dense(1,activation = 'sigmoid'))

model.summary()

#model compile stage
model.compile(loss='binary_crossentropy',optimizer = 'Adam')
# how many time data circulate in this model
model.fit(X_train_scaled,y_train,epochs = 10)
# in this model circulate time set 10

# if first layer 11 * 3 weight  is indicate 0 as a first layer and byas
model.layers[0].get_weights()

model.predict(X_test_scaled)

y_log  = model.predict(X_test_scaled)
# this value convert to o and 1 as we dicided if value > 0.5 then 1 and if value <0.5 vale is 1
y_pred = np.where(y_log > 0.5,1,0)

#find the accuracy in this model
from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)



"""to get more accuracy improve activation function ralue
and use more epochs value

increase number of node
increase hidden layer
"""